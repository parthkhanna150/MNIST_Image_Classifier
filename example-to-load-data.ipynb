{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train_labels.csv', 'train_images.pkl', 'test_images.pkl']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Files are stored in pickle format.\n",
    "#Load them like how you load any pickle. The data is a numpy array\n",
    "import pandas as pd\n",
    "train_images = pd.read_pickle('../input/train_images.pkl')\n",
    "train_labels = pd.read_csv('../input/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b3c7d8acfc830105a5cf04fb957430c65b644a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 64, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e3c1d7b8d0c63e20082273e99aede79da7198f41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d05281a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Let's show image with id 16\n",
    "img_idx = 16\n",
    "\n",
    "plt.title('Label: {}'.format(train_labels.iloc[img_idx]['Category']))\n",
    "plt.imshow(train_images[img_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from skimage.morphology import label, closing, square\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "0a773eb3e19b2e35292f2a8103bd1ce838aa3dd7"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, imgDim):\n",
    "    finalData = np.zeros(shape=(x.shape[0], imgDim, imgDim))\n",
    "    #Loop through every image in provided data\n",
    "    for n in range(x.shape[0]):\n",
    "\n",
    "        #Binarizing the image\n",
    "        currImg = np.array(x[n])\n",
    "        currImg[currImg != 255] = 0 #Non-black pixel--> threshold as a 0.\n",
    "        currImg[currImg == 255] = 1 #255 intensity --> threshold as a 1.\n",
    "        binarizedImg = currImg # >= thresh\n",
    "        labelledCompImg = label(binarizedImg)  #Labels each connected component in binarized image\n",
    "\n",
    "        biggestRegion = regionprops(labelledCompImg) #initialize current maximum connected component\n",
    "        prevLen = 0\n",
    "        #For every connected component, check if it's the biggest in the image.\n",
    "        for region in regionprops(labelledCompImg):\n",
    "            minRow, minCol, maxRow, maxCol = region.bbox #find bounding box\n",
    "            length = max(abs(minRow-maxRow), abs(minCol-maxCol))\n",
    "            if length > prevLen: #compare length of bounding boxes in img\n",
    "                prevLen = length\n",
    "                biggestRegion = region\n",
    "\n",
    "        #Isolate the largest component by cropping it's bounding box\n",
    "        minRow, minCol, maxRow, maxCol = biggestRegion['BoundingBox']\n",
    "        isolatedNum = binarizedImg[min(minRow,maxRow):max(minRow,maxRow), min(minCol,maxCol):max(minCol,maxCol)]\n",
    "        \n",
    "        #Transform to new dimensions 28x28\n",
    "        finalData[n] = resize(isolatedNum, (imgDim,imgDim))\n",
    "\n",
    "        if (n%2000 == 0):\n",
    "            print(\"Currently on example #: \", n)\n",
    "            \n",
    "    return finalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on example #:  0\n",
      "(800, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ce52f47b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xTrain = preprocess(train_images[0:1000], 28) #[0:1000] is just for quick testing, remove for whole training.\n",
    "\n",
    "yTrain = []\n",
    "with open(\"../input/train_labels.csv\", \"r\") as csv_file: #Because this was quicker than Panda\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for lines in csv_reader:\n",
    "        yTrain.append(lines[1])\n",
    "yTrain.remove('Category')\n",
    "\n",
    "#Set the below for the entire 40000 training examples.\n",
    "x_train = xTrain[0:800]\n",
    "y_train = yTrain[0:800]\n",
    "x_valid = xTrain[801:1000]\n",
    "y_valid = yTrain[801:1000]\n",
    "\n",
    "print(x_train.shape)\n",
    "plt.imshow(x_train[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape for encoding.\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)\n",
    "\n",
    "#One-hot encoding\n",
    "number_of_classes = 10\n",
    "y_train = np.array(np_utils.to_categorical(y_train, number_of_classes))\n",
    "y_valid = np.array(np_utils.to_categorical(y_valid, number_of_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
